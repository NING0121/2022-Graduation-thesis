{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 根据语料分别构建源数据词表 和 目标数据词表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append(\"..\")\n",
    "from Utils.Dictionary import Dictionary\n",
    "\n",
    "\n",
    "data_path = \"../Data/Dataset/data.csv\"\n",
    "source_dic_path = \"../Data/source_vocal.pkl\"\n",
    "target_dic_path = \"../Data/target_vocal.pkl\"\n",
    "\n",
    "\n",
    "# 生成 源数据字典 and 目标数据字典\n",
    "source_dic = Dictionary()\n",
    "source_dic.load_from_data(data_path, \"raw_data\")\n",
    "source_dic.dump_to_file(source_dic_path)\n",
    "\n",
    "target_dic = Dictionary()\n",
    "target_dic.load_from_data(data_path, \"raw_data\")\n",
    "target_dic.dump_to_file(target_dic_path)\n",
    "target_dic.word2idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 数据集的划分（如果已经划分好就不必划分）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 文件路径\n",
    "data_path = \"../Data/Dataset/data.csv\"\n",
    "train_data_path = \"../Data/Dataset/train_data.csv\"\n",
    "test_data_path = \"../Data/Dataset/test_data.csv\"\n",
    "\n",
    "# 数据集划分\n",
    "split_ratio = 0.8\n",
    "dataset = pd.read_csv(data_path, index_col=0)\n",
    "train_set = dataset.sample(frac = split_ratio, random_state=0, axis=0)\n",
    "test_set = dataset[~dataset.index.isin(train_set.index)]\n",
    "\n",
    "# 数据集保存\n",
    "train_set.to_csv(train_data_path)\n",
    "test_set.to_csv(test_data_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据增强"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_data</th>\n",
       "      <th>right_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>权益服务：您领取的双突战法指标今天已有信号提醒啦譽快登录大智慧b查看或现在打开链接h://t...</td>\n",
       "      <td>权益服务:您领取的双突战法指标今天已有信号提醒啦,快登录大智慧b查看或现在打开链接h://t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>【亲朋萁牌 】来就送68-668！忸ν   忸主主  砟金?更多好玩等你来 e5.q00k....</td>\n",
       "      <td>【亲朋棋牌】来就送68-668!牛牛斗地主炸金更多好玩等你来e5.q00k.com29634...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>告诉黄某某,速速回家,明天有外访工作人员去家里核实  豆 豆 qian芡 单情况,微信：ht...</td>\n",
       "      <td>告诉黄某某,速速回家,明天有外访工作人员去家里核实豆豆欠账单情况,微信:htsz6666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>你好!天意如此,让你遇见,玷： 18535.c0 领18-188!</td>\n",
       "      <td>你好!天意如此,让你遇见,点:18535.c0领18188!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>授信成功：您7帐号获5首批提现资格镖余额6元譽提现s.s/q?8r2谨防泄露退订回x</td>\n",
       "      <td>授信成功:您7帐号获5首批提现资格,余额6元,提现s.s/q?8r2谨防泄露退订回x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7811</th>\n",
       "      <td>玺诺琥珀：除夕狂欢夜镖今晚漏到爆！珠宝壕礼送到你手软！点7q.o/k5t领取牛气大礼包！（阈...</td>\n",
       "      <td>玺诺琥珀:除夕狂欢夜,今晚漏到爆!珠宝壕礼送到你手软!点7q.o/k5t领取牛气大礼包!(阈...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7812</th>\n",
       "      <td>哇⁢(_3期必中洄血纪划⁢注册就送一百啟冻金 加Ｖ縅解：fp18860274159惦cDw</td>\n",
       "      <td>哇,(3期必中回血计划,注册就送一百启动金加微了解:fp18860274159.cDw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7813</th>\n",
       "      <td>公司贷款有返点孒商贷返千1-1.5抵押贷款150以上千8垫资2个点垫首付4个点2变首4泇3贷...</td>\n",
       "      <td>公司贷款有返点了商贷返千1-1.5抵押贷款150以上千8垫资2个点垫首付4个点2变首4加3贷...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7814</th>\n",
       "      <td>阁下,老哥,你号一水不限攸戯,珫100到137,丛1000到1188,加Q 24773942...</td>\n",
       "      <td>阁下,老哥,你号一水不限游戏,充100到137,充1000到1188,加Q247739423...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7815</th>\n",
       "      <td>哇⁢拎118红孢一閖 ♂你皓有水镖cq⒐跳髙縞镖諟⑤贎赚@ɡ长龙不斷镖湜10萬： https...</td>\n",
       "      <td>哇,领118红包一水你号有水,cq9跳高高,提5万,ɡ长龙不断,提10万:https:u81...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7816 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               raw_data  \\\n",
       "0     权益服务：您领取的双突战法指标今天已有信号提醒啦譽快登录大智慧b查看或现在打开链接h://t...   \n",
       "1     【亲朋萁牌 】来就送68-668！忸ν   忸主主  砟金?更多好玩等你来 e5.q00k....   \n",
       "2     告诉黄某某,速速回家,明天有外访工作人员去家里核实  豆 豆 qian芡 单情况,微信：ht...   \n",
       "3                     你好!天意如此,让你遇见,玷： 18535.c0 领18-188!   \n",
       "4            授信成功：您7帐号获5首批提现资格镖余额6元譽提现s.s/q?8r2谨防泄露退订回x   \n",
       "...                                                 ...   \n",
       "7811  玺诺琥珀：除夕狂欢夜镖今晚漏到爆！珠宝壕礼送到你手软！点7q.o/k5t领取牛气大礼包！（阈...   \n",
       "7812      哇⁢(_3期必中洄血纪划⁢注册就送一百啟冻金 加Ｖ縅解：fp18860274159惦cDw   \n",
       "7813  公司贷款有返点孒商贷返千1-1.5抵押贷款150以上千8垫资2个点垫首付4个点2变首4泇3贷...   \n",
       "7814  阁下,老哥,你号一水不限攸戯,珫100到137,丛1000到1188,加Q 24773942...   \n",
       "7815  哇⁢拎118红孢一閖 ♂你皓有水镖cq⒐跳髙縞镖諟⑤贎赚@ɡ长龙不斷镖湜10萬： https...   \n",
       "\n",
       "                                             right_data  \n",
       "0     权益服务:您领取的双突战法指标今天已有信号提醒啦,快登录大智慧b查看或现在打开链接h://t...  \n",
       "1     【亲朋棋牌】来就送68-668!牛牛斗地主炸金更多好玩等你来e5.q00k.com29634...  \n",
       "2          告诉黄某某,速速回家,明天有外访工作人员去家里核实豆豆欠账单情况,微信:htsz6666  \n",
       "3                        你好!天意如此,让你遇见,点:18535.c0领18188!  \n",
       "4            授信成功:您7帐号获5首批提现资格,余额6元,提现s.s/q?8r2谨防泄露退订回x  \n",
       "...                                                 ...  \n",
       "7811  玺诺琥珀:除夕狂欢夜,今晚漏到爆!珠宝壕礼送到你手软!点7q.o/k5t领取牛气大礼包!(阈...  \n",
       "7812        哇,(3期必中回血计划,注册就送一百启动金加微了解:fp18860274159.cDw  \n",
       "7813  公司贷款有返点了商贷返千1-1.5抵押贷款150以上千8垫资2个点垫首付4个点2变首4加3贷...  \n",
       "7814  阁下,老哥,你号一水不限游戏,充100到137,充1000到1188,加Q247739423...  \n",
       "7815  哇,领118红包一水你号有水,cq9跳高高,提5万,ɡ长龙不断,提10万:https:u81...  \n",
       "\n",
       "[7816 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "from Utils.VariantNeedleman_Wunsch import VariantNW\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "# 寻找可疑变异\n",
    "def findVariant(seq_1, seq_2):\n",
    "    variant_dic = {}\n",
    "    for variant, right in zip(seq_1, seq_2):\n",
    "        \n",
    "        if isVariant(variant, right):\n",
    "            if right not in variant_dic.keys():\n",
    "                value = [variant]\n",
    "                variant_dic[right] = value\n",
    "            else:\n",
    "                value = variant_dic[right]\n",
    "                value.append(variant)\n",
    "                variant_dic[right] = value\n",
    "\n",
    "    return variant_dic\n",
    "\n",
    "# 筛选变体字典\n",
    "def filterVariant(variant_dic, remove_AandD = True, remove_single = True, remove_ratio = 0.5):\n",
    "    variant_dic_2 = variant_dic.copy()\n",
    "\n",
    "    for key, value in variant_dic.items():\n",
    "\n",
    "        if (key.encode(\"utf-8\").isalpha() or key.isdigit()) and remove_AandD:\n",
    "            delete_key = True\n",
    "\n",
    "        if len(variant_dic[key]) == 1 and remove_single:\n",
    "            delete_key = True\n",
    "        \n",
    "        if delete_key:\n",
    "            del variant_dic_2[key]\n",
    "        else:\n",
    "            for val in value:\n",
    "                variantNW.set_seqs(key, val)\n",
    "                variantNW.propagate()\n",
    "                aligned_seq1, aligned_seq2 = variantNW.traceback()\n",
    "                score = variantNW.get_aligned_seq_score(aligned_seq1, aligned_seq2).pop()\n",
    "                if score < remove_ratio:\n",
    "                    variant_dic[key].remove(val)\n",
    "                \n",
    "    return variant_dic_2\n",
    "\n",
    "\n",
    "# 判断是否是变异\n",
    "def isVariant(char1, char2):\n",
    "    if char1 == char2 or char1 == '[GAP]' or char2 == '[GAP]':\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "# 生成变异数据\n",
    "def genVariant(variant_dic, seq_1, seq_2):\n",
    "    \n",
    "    raw_seq_1 = seq_1.copy()\n",
    "\n",
    "    for variant, right in zip(seq_1, seq_2):\n",
    "        \n",
    "        if isVariant(variant, right):\n",
    "            if right in variant_dic.keys():\n",
    "                a = random.choice(variant_dic[right])\n",
    "                while a == variant:\n",
    "                    a = random.choice(variant_dic[right])\n",
    "                seq_1[seq_1.index(variant)] = a\n",
    "\n",
    "    if seq_1 == raw_seq_1:\n",
    "        return 0, 0\n",
    "    else:\n",
    "        return seq_1, seq_2\n",
    "\n",
    "\n",
    "variantNW = VariantNW()\n",
    "\n",
    "# 读取数据\n",
    "data = pd.read_csv(\"../Data/Dataset/train_data.csv\", index_col=0).reset_index(drop=True)\n",
    "with open(\"../Data/variant_dic_remove_re.json\", \"r\", encoding='UTF-8') as f:\n",
    "    variant_dic = json.load(f)\n",
    "\n",
    "\n",
    "raw_data = []\n",
    "right_data = []\n",
    "for row in data.iterrows():\n",
    "    seq1 = row[1][0]\n",
    "    seq2 = row[1][1]\n",
    "    variantNW.set_seqs(seq1, seq2)\n",
    "    variantNW.propagate()\n",
    "    aligned_seq1, aligned_seq2 = variantNW.traceback()\n",
    "    seq1,seq2 = genVariant(variant_dic, aligned_seq1, aligned_seq2)\n",
    "    if seq1 == 0:\n",
    "        continue\n",
    "    else:\n",
    "        try:\n",
    "            seq1 = \"\".join(seq1).replace(\"[GAP]\",\"\")\n",
    "            seq2 = \"\".join(seq2).replace(\"[GAP]\",\"\")\n",
    "        except:\n",
    "            pass\n",
    "        if row[0] % 1000 == 0:\n",
    "            print(1)\n",
    "        raw_data.append(seq1)\n",
    "        right_data.append(seq2)\n",
    "dataframe = pd.DataFrame({\"raw_data\":raw_data, \"right_data\":right_data})\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.to_csv(\"../Data/Dataset/train_data_supply_0409.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_1 = pd.read_csv(\"../Data/Dataset/train_data_supply_0409.csv\", index_col=0).sample(frac=0.15, axis=0)\n",
    "data_2 = pd.read_csv(\"../Data/Dataset/train_data.csv\", index_col=0)\n",
    "data_1 = pd.concat([data_1, data_2], axis=0, ignore_index=True)\n",
    "data_1.to_csv(\"../Data/Dataset/train_data_supply.csv\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3d696f3826b7c7df140d5da393a635d37b06efd5c1eee0ae51f5f6acb9f78285"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
