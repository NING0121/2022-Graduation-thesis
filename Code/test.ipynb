{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dictionary from ../Data/source_vocal.pkl\n",
      "loading dictionary from ../Data/target_vocal.pkl\n",
      "9086\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3603"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from Utils import VariantWordDataset\n",
    "\n",
    "train_set = VariantWordDataset(\"train\", \"../Data/source_vocal.pkl\", \"../Data/target_vocal.pkl\")\n",
    "print(train_set.__len__())\n",
    "train_set.__getitem__(1)\n",
    "len(train_set.target_dic.word2idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000e+00, 1.0000e+00],\n",
      "        [1.2200e+02, 2.1380e+03],\n",
      "        [3.4200e+03, 3.5600e+03],\n",
      "        [3.1550e+03, 1.9540e+03],\n",
      "        [1.8970e+03, 8.3500e+02],\n",
      "        [4.5300e+02, 1.3660e+03],\n",
      "        [1.8810e+03, 5.0000e+00],\n",
      "        [1.9380e+03, 2.0840e+03],\n",
      "        [3.5570e+03, 8.3700e+02],\n",
      "        [1.7110e+03, 1.5040e+03],\n",
      "        [4.1000e+01, 3.2020e+03],\n",
      "        [1.3770e+03, 7.1600e+02],\n",
      "        [2.3510e+03, 3.3590e+03]])\n",
      "tensor([[1.0000e+00, 1.0000e+00],\n",
      "        [1.2200e+02, 2.1380e+03],\n",
      "        [3.4200e+03, 3.5600e+03],\n",
      "        [3.1550e+03, 1.9540e+03],\n",
      "        [1.8970e+03, 8.3500e+02],\n",
      "        [4.5300e+02, 1.3660e+03],\n",
      "        [1.8810e+03, 5.0000e+00],\n",
      "        [1.9380e+03, 2.0840e+03],\n",
      "        [3.5570e+03, 8.3700e+02],\n",
      "        [1.7110e+03, 1.5040e+03],\n",
      "        [4.1000e+01, 3.2020e+03],\n",
      "        [1.3770e+03, 7.1600e+02]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.Tensor([[   1,    1],\n",
    "        [ 122, 2138],\n",
    "        [3420, 3560],\n",
    "        [3155, 1954],\n",
    "        [1897,  835],\n",
    "        [ 453, 1366],\n",
    "        [1881,    5],\n",
    "        [1938, 2084],\n",
    "        [3557,  837],\n",
    "        [1711, 1504],\n",
    "        [  41, 3202],\n",
    "        [1377,  716],\n",
    "        [2351, 3359]])\n",
    "print(a)\n",
    "print(a[:-1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  50, 2339],\n",
      "        [4279, 1465],\n",
      "        [4176, 2266],\n",
      "        [3678, 2453],\n",
      "        [3255,  562],\n",
      "        [5126,  326],\n",
      "        [ 805, 3752],\n",
      "        [5804, 1822],\n",
      "        [3604, 2096],\n",
      "        [2950, 5654],\n",
      "        [3457,  265],\n",
      "        [2422, 4252],\n",
      "        [2813, 3997],\n",
      "        [5761,  265],\n",
      "        [1164,  265],\n",
      "        [4189, 4252],\n",
      "        [2056,  597],\n",
      "        [2953,  392],\n",
      "        [4100, 2307],\n",
      "        [1891,  326],\n",
      "        [3496,  326],\n",
      "        [5484,  326],\n",
      "        [2653, 3544],\n",
      "        [4228,    5],\n",
      "        [ 960, 3926],\n",
      "        [5345, 1283],\n",
      "        [3492,  326],\n",
      "        [ 470,  326],\n",
      "        [5055, 2419],\n",
      "        [1660, 1700],\n",
      "        [2253, 1902],\n",
      "        [4990, 2381],\n",
      "        [3215, 3856],\n",
      "        [ 512, 5740],\n",
      "        [1628, 5446],\n",
      "        [1151, 4430],\n",
      "        [ 578, 1062],\n",
      "        [1191, 1822],\n",
      "        [5092,  326],\n",
      "        [ 206, 5248],\n",
      "        [ 719, 4088],\n",
      "        [3756, 1601],\n",
      "        [3118, 3889],\n",
      "        [ 693, 3497],\n",
      "        [ 693, 3497],\n",
      "        [1377, 2050],\n",
      "        [1601, 1601],\n",
      "        [5513, 1372],\n",
      "        [1601, 4848],\n",
      "        [5248, 1482],\n",
      "        [1601,  693],\n",
      "        [1372, 1902],\n",
      "        [2097, 1633],\n",
      "        [ 693, 2854],\n",
      "        [3889,  265],\n",
      "        [3013, 1204],\n",
      "        [ 276, 4547],\n",
      "        [ 552, 4252],\n",
      "        [   0, 1204],\n",
      "        [   0,  326],\n",
      "        [   0, 1656],\n",
      "        [   0,  708],\n",
      "        [   0, 1990],\n",
      "        [   0, 1416],\n",
      "        [   0, 1656]])\n",
      "tensor([[   0, 1656],\n",
      "        [   0, 1416],\n",
      "        [   0, 1990],\n",
      "        [   0,  708],\n",
      "        [   0, 1656],\n",
      "        [   0,  326],\n",
      "        [   0, 1204],\n",
      "        [ 552, 4252],\n",
      "        [ 276, 4547],\n",
      "        [3013, 1204],\n",
      "        [3889,  265],\n",
      "        [ 693, 2854],\n",
      "        [2097, 1633],\n",
      "        [1372, 1902],\n",
      "        [1601,  693],\n",
      "        [5248, 1482],\n",
      "        [1601, 4848],\n",
      "        [5513, 1372],\n",
      "        [1601, 1601],\n",
      "        [1377, 2050],\n",
      "        [ 693, 3497],\n",
      "        [ 693, 3497],\n",
      "        [3118, 3889],\n",
      "        [3756, 1601],\n",
      "        [ 719, 4088],\n",
      "        [ 206, 5248],\n",
      "        [5092,  326],\n",
      "        [1191, 1822],\n",
      "        [ 578, 1062],\n",
      "        [1151, 4430],\n",
      "        [1628, 5446],\n",
      "        [ 512, 5740],\n",
      "        [3215, 3856],\n",
      "        [4990, 2381],\n",
      "        [2253, 1902],\n",
      "        [1660, 1700],\n",
      "        [5055, 2419],\n",
      "        [ 470,  326],\n",
      "        [3492,  326],\n",
      "        [5345, 1283],\n",
      "        [ 960, 3926],\n",
      "        [4228,    5],\n",
      "        [2653, 3544],\n",
      "        [5484,  326],\n",
      "        [3496,  326],\n",
      "        [1891,  326],\n",
      "        [4100, 2307],\n",
      "        [2953,  392],\n",
      "        [2056,  597],\n",
      "        [4189, 4252],\n",
      "        [1164,  265],\n",
      "        [5761,  265],\n",
      "        [2813, 3997],\n",
      "        [2422, 4252],\n",
      "        [3457,  265],\n",
      "        [2950, 5654],\n",
      "        [3604, 2096],\n",
      "        [5804, 1822],\n",
      "        [ 805, 3752],\n",
      "        [5126,  326],\n",
      "        [3255,  562],\n",
      "        [3678, 2453],\n",
      "        [4176, 2266],\n",
      "        [4279, 1465],\n",
      "        [  50, 2339]])\n",
      "tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True,  True,  True,  True],\n",
      "        [False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False]])\n",
      "tensor([[7],\n",
      "        [0]])\n",
      "67\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "# from torch.utils.data.dataloader import default_collate\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "def generate_square_subsequent_mask(tgt_seq_len, device):\n",
    "\n",
    "    mask = (torch.triu(torch.ones((tgt_seq_len, tgt_seq_len), device=device)) == 1).transpose(0, 1)\n",
    "\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "\n",
    "    return mask\n",
    "\n",
    "def create_mask( src, tgt, device='cpu'):\n",
    "    src_seq_len = src.shape[0]\n",
    "\n",
    "    tgt_seq_len = tgt.shape[0]\n",
    "\n",
    "    # Decoder的注意力Mask输入，用于掩盖当前position之后的position，所以这里是一个对称矩阵\n",
    "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len, device)  # [tgt_len,tgt_len]\n",
    "\n",
    "    # Encoder的注意力Mask输入，这部分其实对于Encoder来说是没有用的，所以这里全是0\n",
    "    src_mask = torch.zeros((src_seq_len, src_seq_len), device=device).type(torch.bool)\n",
    "\n",
    "    # 用于mask掉Encoder的Token序列中的padding部分,[batch_size, src_len]\n",
    "    src_padding_mask = (src == 0).transpose(0, 1)\n",
    "\n",
    "    # 用于mask掉Decoder的Token序列中的padding部分,batch_size, tgt_len\n",
    "    tgt_padding_mask = (tgt == 0).transpose(0, 1)\n",
    "\n",
    "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask\n",
    "\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=2, collate_fn=train_set.generate_batch,\n",
    "                                               shuffle=False)\n",
    "for src, tgt in train_loader:\n",
    "    print(src)\n",
    "    print(src.shape)\n",
    "    src = src.transpose(0,1)\n",
    "    print(src)\n",
    "    print(src.shape)\n",
    "    # tgt_input = tgt[:-1, :]\n",
    "\n",
    "    # tgt_out = tgt[1:, :]\n",
    "\n",
    "    # src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
    "\n",
    "    \n",
    "    # print(\"src shape:\", src.shape)  # [de_tensor_len,batch_size]\n",
    "\n",
    "    # print(\"src_padding_mask shape (batch_size, src_len): \", src_padding_mask.shape)\n",
    "\n",
    "    # print(\"tgt input shape:\", tgt_input.shape)\n",
    "\n",
    "    # print(\"tgt_padding_mask shape: (batch_size, tgt_len) \", tgt_padding_mask.shape)\n",
    "    # print(\"tgt output shape:\", tgt_out.shape)\n",
    "\n",
    "    # print(\"tgt_mask shape (tgt_len,tgt_len): \", tgt_mask.shape)\n",
    "    # print(\"src_mask shape (tgt_len,tgt_len): \", src_mask.shape)\n",
    "    # print(\"src_padding_mask shape (batch_size, src_len): \", src_padding_mask.shape)\n",
    "\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Model.TranslationModel import TranslationModel\n",
    "from Model.config import Config\n",
    "from torchtext.data.metrics import bleu_score\n",
    "from Utils.Dictionary import Dictionary\n",
    "\n",
    "config = Config()\n",
    "dic = Dictionary.load_from_file(config.target_dic_path)\n",
    "\n",
    "translation_model = TranslationModel(src_vocab_size=len(train_set.source_dic.word2idx),\n",
    "                                         tgt_vocab_size=len(train_set.target_dic.word2idx),\n",
    "                                         d_model=config.d_model,\n",
    "                                         nhead=config.num_head,\n",
    "                                         num_encoder_layers=config.num_encoder_layers,\n",
    "                                         num_decoder_layers=config.num_decoder_layers,\n",
    "                                         dim_feedforward=config.dim_feedforward,\n",
    "                                         dropout=config.dropout)\n",
    "\n",
    "def translate(tensor):\n",
    "    result = [dic.idx2word[i] for i in tensor.numpy()]\n",
    "    return result\n",
    "\n",
    "\n",
    "for src, tgt in train_loader:\n",
    "    src = src.to(config.device)  # [src_len, batch_size]\n",
    "    tgt = tgt.to(config.device)\n",
    "    tgt_input = tgt[:-1, :]  # 解码部分的输入, [tgt_len,batch_size]\n",
    "    src_mask, tgt_mask, src_padding_mask, tgt_padding_mask \\\n",
    "    = create_mask(src, tgt_input, config.device)\n",
    "    logits = translation_model(\n",
    "    src=src,  # Encoder的token序列输入，[src_len,batch_size]\n",
    "    tgt=tgt_input,  # Decoder的token序列输入,[tgt_len,batch_size]\n",
    "    src_mask=src_mask,  # Encoder的注意力Mask输入，这部分其实对于Encoder来说是没有用的\n",
    "    tgt_mask=tgt_mask,\n",
    "    # Decoder的注意力Mask输入，用于掩盖当前position之后的position [tgt_len,tgt_len]\n",
    "    src_key_padding_mask=src_padding_mask,  # 用于mask掉Encoder的Token序列中的padding部分\n",
    "    tgt_key_padding_mask=tgt_padding_mask,  # 用于mask掉Decoder的Token序列中的padding部分\n",
    "    memory_key_padding_mask=src_padding_mask)  # 用于mask掉Encoder的Token序列中的padding部分\n",
    "\n",
    "    tgt_out = tgt[1:, :]  # 解码部分的真实值  shape: [tgt_len,batch_size]\n",
    "    # logits 输出shape为[tgt_len,batch_size,tgt_vocab_size]\n",
    "    # bleu_score(tgt_out.t().squeeze(), tgt_input.t().squeeze())\n",
    "\n",
    "\n",
    "    print(logits.reshape(-1, logits.shape[-1]))\n",
    "    # for i, j in zip(tgt_out.t(), tgt_input.t()):\n",
    "    #     i = [translate(i)]\n",
    "    #     j = [[translate(j)]]\n",
    "    #     print(i)\n",
    "    #     print(j)\n",
    "    #     print(bleu_score(i, j))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from config import Config\n",
    "from Model.TranslationModel import TranslationModel\n",
    "import torch\n",
    "import time\n",
    "import os\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "def accuracy(logits, y_true, PAD_IDX):\n",
    "    \"\"\"\n",
    "    :param logits:  [tgt_len,batch_size,tgt_vocab_size]\n",
    "    :param y_true:  [tgt_len,batch_size]\n",
    "    :param PAD_IDX:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    y_pred = logits.transpose(0, 1).argmax(axis=2).reshape(-1)\n",
    "    # 将 [tgt_len,batch_size,tgt_vocab_size] 转成 [batch_size, tgt_len,tgt_vocab_size]\n",
    "    y_true = y_true.transpose(0, 1).reshape(-1)\n",
    "    # 将 [tgt_len,batch_size] 转成 [batch_size， tgt_len]\n",
    "    acc = y_pred.eq(y_true)  # 计算预测值与正确值比较的情况\n",
    "    mask = torch.logical_not(y_true.eq(PAD_IDX))  # 找到真实标签中，mask位置的信息。 mask位置为FALSE，非mask位置为TRUE\n",
    "    acc = acc.logical_and(mask)  # 去掉acc中mask的部分\n",
    "    correct = acc.sum().item()\n",
    "    total = mask.sum().item()\n",
    "    return float(correct) / total, correct, total\n",
    "\n",
    "def train_model(config):\n",
    "    logging.info(\"############载入数据集############\")\n",
    "\n",
    "    train_set = VariantWordDataset(\"train\", \"../Data/source_vocal.pkl\", \"../Data/target_vocal.pkl\")\n",
    "    valid_set = VariantWordDataset(\"test\", \"../Data/source_vocal.pkl\", \"../Data/target_vocal.pkl\")\n",
    "\n",
    "\n",
    "    logging.info(\"############划分数据集############\")\n",
    "\n",
    "    train_set_loader = DataLoader(train_set, batch_size=config.batch_size, \n",
    "                                    collate_fn=train_set.generate_batch, shuffle=False)\n",
    "\n",
    "    valid_set_loader = DataLoader(valid_set, batch_size=config.batch_size, \n",
    "                                    collate_fn=valid_set.generate_batch, shuffle=False)\n",
    "\n",
    "\n",
    "    logging.info(\"############初始化模型############\")\n",
    "    translation_model = TranslationModel(src_vocab_size=len(train_set.source_dic.word2idx),\n",
    "                                         tgt_vocab_size=len(train_set.target_dic.word2idx),\n",
    "                                         d_model=config.d_model,\n",
    "                                         nhead=config.num_head,\n",
    "                                         num_encoder_layers=config.num_encoder_layers,\n",
    "                                         num_decoder_layers=config.num_decoder_layers,\n",
    "                                         dim_feedforward=config.dim_feedforward,\n",
    "                                         dropout=config.dropout)\n",
    "\n",
    "    \n",
    "\n",
    "    model_save_path = os.path.join(config.model_save_dir, 'model.pkl')\n",
    "\n",
    "    if os.path.exists(model_save_path):\n",
    "        loaded_paras = torch.load(model_save_path)\n",
    "        translation_model.load_state_dict(loaded_paras)\n",
    "        logging.info(\"#### 成功载入已有模型，进行追加训练...\")\n",
    "\n",
    "\n",
    "    translation_model = translation_model.to(config.device)\n",
    "\n",
    "\n",
    "    loss_fn = torch.nn.CrossEntropyLoss(ignore_index=train_set.PAD_IDX)\n",
    "    optimizer = torch.optim.Adam(translation_model.parameters(),\n",
    "                                 lr=0.,\n",
    "                                 betas=(config.beta1, config.beta2), eps=config.epsilon)\n",
    "\n",
    "    # lr_scheduler = CustomSchedule(config.d_model, optimizer=optimizer)\n",
    "\n",
    "    translation_model.train()\n",
    "    for epoch in  range(config.epochs):\n",
    "        losses = 0\n",
    "        start_time = time.time()\n",
    "        for idx, (src, tgt) in tqdm(enumerate(train_set_loader)):\n",
    "            src = src.to(config.device)  # [src_len, batch_size]\n",
    "            tgt = tgt.to(config.device)\n",
    "            tgt_input = tgt[:-1, :]  # 解码部分的输入, [tgt_len,batch_size]\n",
    "            src_mask, tgt_mask, src_padding_mask, tgt_padding_mask \\\n",
    "                = create_mask(src, tgt_input, config.device)\n",
    "            logits = translation_model(\n",
    "                src=src,  # Encoder的token序列输入，[src_len,batch_size]\n",
    "                tgt=tgt_input,  # Decoder的token序列输入,[tgt_len,batch_size]\n",
    "                src_mask=src_mask,  # Encoder的注意力Mask输入，这部分其实对于Encoder来说是没有用的\n",
    "                tgt_mask=tgt_mask,\n",
    "                # Decoder的注意力Mask输入，用于掩盖当前position之后的position [tgt_len,tgt_len]\n",
    "                src_key_padding_mask=src_padding_mask,  # 用于mask掉Encoder的Token序列中的padding部分\n",
    "                tgt_key_padding_mask=tgt_padding_mask,  # 用于mask掉Decoder的Token序列中的padding部分\n",
    "                memory_key_padding_mask=src_padding_mask)  # 用于mask掉Encoder的Token序列中的padding部分\n",
    "            # logits 输出shape为[tgt_len,batch_size,tgt_vocab_size]\n",
    "            optimizer.zero_grad()\n",
    "            tgt_out = tgt[1:, :]  # 解码部分的真实值  shape: [tgt_len,batch_size]\n",
    "            loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "            # [tgt_len*batch_size, tgt_vocab_size] with [tgt_len*batch_size, ]\n",
    "            loss.backward()\n",
    "            # lr_scheduler.step()\n",
    "            optimizer.step()\n",
    "            losses += loss.item()\n",
    "            acc, _, _ = accuracy(logits, tgt_out, train_set.PAD_IDX)\n",
    "            msg = f\"Epoch: {epoch}, Batch[{idx}/{len(train_set_loader)}], Train loss :{loss.item():.3f}, Train acc: {acc}\"\n",
    "            logging.info(msg)\n",
    "        end_time = time.time()\n",
    "        train_loss = losses / len(train_set_loader)\n",
    "        msg = f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Epoch time = {(end_time - start_time):.3f}s\"\n",
    "        logging.info(msg)\n",
    "\n",
    "\n",
    "\n",
    "        if epoch % 2 == 0:\n",
    "            acc = evaluate(config, valid_set_loader, translation_model, dataset)\n",
    "            logging.info(f\"Accuracy on validation{acc:.3f}\")\n",
    "            torch.save(translation_model.state_dict(), model_save_path)\n",
    "\n",
    "\n",
    "def evaluate(config, valid_iter, model, dataset):\n",
    "    model.eval()\n",
    "    correct, totals = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for idx, (src, tgt) in enumerate(valid_iter):\n",
    "            src = src.to(config.device)\n",
    "            tgt = tgt.to(config.device)\n",
    "            tgt_input = tgt[:-1, :]  # 解码部分的输入\n",
    "\n",
    "            src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = \\\n",
    "                create_mask(src, tgt_input, device=config.device)\n",
    "\n",
    "            logits = model(src=src,  # Encoder的token序列输入，\n",
    "                           tgt=tgt_input,  # Decoder的token序列输入\n",
    "                           src_mask=src_mask,  # Encoder的注意力Mask输入，这部分其实对于Encoder来说是没有用的\n",
    "                           tgt_mask=tgt_mask,  # Decoder的注意力Mask输入，用于掩盖当前position之后的position\n",
    "                           src_key_padding_mask=src_padding_mask,  # 用于mask掉Encoder的Token序列中的padding部分\n",
    "                           tgt_key_padding_mask=tgt_padding_mask,  # 用于mask掉Decoder的Token序列中的padding部分\n",
    "                           memory_key_padding_mask=src_padding_mask)  # 用于mask掉Encoder的Token序列中的padding部分\n",
    "            tgt_out = tgt[1:, :]  # 解码部分的真实值  shape: [tgt_len,batch_size]\n",
    "            _, c, t = accuracy(logits, tgt_out, valid_iter.PAD_IDX)\n",
    "            correct += c\n",
    "            totals += t\n",
    "    model.train()\n",
    "    return float(correct) / totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from Model.config import Config\n",
    "config = Config()\n",
    "train_model(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from Model.TranslationModel import TranslationModel\n",
    "from Model.config import Config\n",
    "import torch\n",
    "config = Config()\n",
    "translation_model = TranslationModel(src_vocab_size=config.source_vocab_size,\n",
    "                                        tgt_vocab_size=config.target_vocab_size,\n",
    "                                        d_model=config.d_model,\n",
    "                                        nhead=config.num_head,\n",
    "                                        num_encoder_layers=config.num_encoder_layers,\n",
    "                                        num_decoder_layers=config.num_decoder_layers,\n",
    "                                        dim_feedforward=config.dim_feedforward,\n",
    "                                        dropout=config.dropout)\n",
    "\n",
    "load_param = torch.load(\"../cache/model.pkl\", map_location=torch.device('cpu'))\n",
    "translation_model.load_state_dict(load_param)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Utils.Dictionary import Dictionary\n",
    "dic = Dictionary.load_from_file(\"../Data/source_vocal.pkl\")\n",
    "len(dic.word2idx)\n",
    "dic.word2idx\n",
    "dic.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torchtext.data.metrics import bleu_score\n",
    "# candidate_corpus = [['权', '益', '服', '务', ':', '您', '领', '取', '的', '双', '突', '战', '法', '指']]\n",
    "# references_corpus = [[['权', '益', '服', '务', ':', '您', '领', '取', '的', '双', '突', '战', '法']]]\n",
    "# candidate_corpus = ['权', '益', '服', '务']\n",
    "# references_corpus = ['权', '益', '服', '务']\n",
    "candidate_corpus = [['权', '益', '服', '务', ':', '您', '领', '取', '的', '双', '突', '战', '法', '指', '标', '今', '天', '已', '有', '信', '号', '提', '醒', '啦', ',', '快', '登', '录', '大', '智', '慧', 'b', '查', '看', '或', '现', '在', '打', '开', '链', '接', 'h', ':', '/', '/', 't', '.', 'v', '.', 'e', '.', 'c', 'd', '/', 'q', '使', '用', '.', '[EOS]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']]\n",
    "references_corpus = [[['权', '益', '服', '务', ':', '您', '领', '取', '的', '双', '突', '战', '法', '指', '标', '今', '天', '已', '有', '信', '号', '提', '醒', '啦', ',', '快', '登', '录', '大', '智', '慧', 'b', '查', '看', '或', '现', '在', '打', '开', '链', '接', 'h', ':', '/', '/', 't', '.', 'v', '.', 'e', '.', 'c', 'd', '/', 'm', '使', '用', '.', '[EOS]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']]]\n",
    "\n",
    "print(len(candidate_corpus[0]))\n",
    "print(len(references_corpus[0]))\n",
    "print(references_corpus[0][0])\n",
    "bleu_score(candidate_corpus, references_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([20., 22., 24., 26., 28., 30.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "a = torch.Tensor([[10,11,12,13,14,15],[10,11,12,13,14,15]])\n",
    "a.shape\n",
    "a.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/environment/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [1.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F \n",
    "a = torch.Tensor([[1],[2],[3]])\n",
    "b = torch.Tensor([[1],[2],[3]])\n",
    "torch.cat((a,b), 1)\n",
    "a.shape[0]\n",
    "a.size(0)\n",
    "torch.zeros(8,1,device=\"cpu\")\n",
    "a = torch.Tensor([[0.3, 0.7]])\n",
    "F.softmax(a)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b114295533213be714c497b6c7c7c36862ca698da8b4418201631177dea05d47"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
