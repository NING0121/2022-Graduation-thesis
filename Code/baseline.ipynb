{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from Utils import VariantWordDataset, Config\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dictionary from ../Data/source_vocal.pkl\n",
      "loading dictionary from ../Data/target_vocal.pkl\n",
      "loading dictionary from ../Data/source_vocal.pkl\n",
      "loading dictionary from ../Data/target_vocal.pkl\n",
      "Train size: 9086\n"
     ]
    }
   ],
   "source": [
    "# 实例化全局参数 Config 对象\n",
    "config = Config()\n",
    "\n",
    "\n",
    "# 构建数据集\n",
    "train_set = VariantWordDataset(\"train\", config.source_dic_path, config.target_dic_path)\n",
    "valid_set = VariantWordDataset(\"test\", config.source_dic_path, config.target_dic_path)\n",
    "print(f\"Train size: {len(train_set)}\")\n",
    "\n",
    "# 构建data_loader\n",
    "n_cpu = os.cpu_count()\n",
    "train_dataloader = DataLoader(train_set, batch_size=config.batch_size, shuffle=True, collate_fn=train_set.generate_batch, num_workers=n_cpu)\n",
    "valid_dataloader = DataLoader(valid_set, batch_size=config.batch_size, shuffle=False, collate_fn=valid_set.generate_batch, num_workers=n_cpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Model.BaselineModel import BaselineModel\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "# import wandb\n",
    "\n",
    "# 初始化 wandb\n",
    "# wandb.init(project=\"Graduation_project\")\n",
    "\n",
    "# 模型初始化\n",
    "model = BaselineModel(config)\n",
    "\n",
    "# # wandb logger\n",
    "# wandb_logger = WandbLogger(project = \"Graduation_project\",\n",
    "#                            name = 'Transformer-CrossEL-lr-0.02',\n",
    "#                            save_dir = '../Logs',\n",
    "#                            log_model=\"all\")\n",
    "\n",
    "# # 模型参数保存\n",
    "# checkpoint_callback = ModelCheckpoint(\n",
    "#     monitor=\"valid_accuracy\",\n",
    "#     dirpath=\"../Weights\",\n",
    "#     filename=\"Baseline-Transformer-CrossEntropyLoss-{epoch:02d}-{valid_accuracy:.2f}\",\n",
    "#     save_top_k=3,\n",
    "#     mode=\"max\",\n",
    "# )\n",
    "\n",
    "# # 训练 Trainer 定义\n",
    "# trainer = pl.Trainer(\n",
    "#     max_epochs=5, \n",
    "#     gpus=0,\n",
    "#     logger = wandb_logger,\n",
    "#     callbacks=[checkpoint_callback]\n",
    "#     )\n",
    "\n",
    "\n",
    "# # 模型训练\n",
    "# trainer.fit(\n",
    "#     model, \n",
    "#     train_dataloaders=train_dataloader, \n",
    "#     val_dataloaders=valid_dataloader\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dictionary from ../Data/source_vocal.pkl\n",
      "loading dictionary from ../Data/target_vocal.pkl\n",
      "德语：9306你好,鉴于你良好的信誉,特聘请你~来我店帮忙工作（350/天）咨询,Q:707941883.\n",
      "翻译： 又 馥 崭 燕 元 元 雨 雨 雨 雨 雨 雨 猎 雨 雨 雨 雨 實 實 實 實 實 實 實 實 莱 實 實 實 實 實 實 實 實 實 實 實 筛 筛 筛 雨 雨 莱 莱 實 缇 實 實 實 實 實 雨 雨 猎\n",
      "英语：9306你好,鉴于你良好的信誉,特聘请你来我店帮忙工作(350天)咨询,Q:707941883.\n",
      "[['9', '3', '0', '6', '你', '好', ',', '鉴', '于', '你', '良', '好', '的', '信', '誉', ',', '特', '聘', '请', '你', '~', '来', '我', '店', '帮', '忙', '工', '作', '（', '3', '5', '0', '/', '天', '）', '咨', '询', ',', 'Q', ':', '7', '0', '7', '9', '4', '1', '8', '8', '3', '.']]\n",
      "[[['9', '3', '0', '6', '你', '好', ',', '鉴', '于', '你', '良', '好', '的', '信', '誉', ',', '特', '聘', '请', '你', '来', '我', '店', '帮', '忙', '工', '作', '(', '3', '5', '0', '天', ')', '咨', '询', ',', 'Q', ':', '7', '0', '7', '9', '4', '1', '8', '8', '3', '.']]]\n",
      "0.8034114837646484\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from Model.TranslationModel import TranslationModel\n",
    "from Utils.Variant_word import VariantWordDataset\n",
    "import torch\n",
    "from torchtext.data.metrics import bleu_score\n",
    "\n",
    "def translate(model, src, data_loader, config):\n",
    "    \n",
    "    source_dic = data_loader.source_dic    \n",
    "    target_dic = data_loader.target_dic\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    tokens = [source_dic.word2idx[i] for i in list(src)] # 构造一个样本\n",
    "    num_tokens = len(tokens)\n",
    "    src = (torch.LongTensor(tokens).reshape(num_tokens, 1))  # 将src_len 作为第一个维度\n",
    "    tgt_tokens = greedy_decode(model, src, max_len=num_tokens + 5,\n",
    "                                start_symbol=config.BOS_IDX, config=config).flatten()  # 解码的预测结果\n",
    "    \n",
    "    return \" \".join([target_dic.idx2word[int(tok)] for tok in tgt_tokens]).replace(\"[BOS]\", \"\").replace(\"[EOS]\", \"\")\n",
    "\n",
    "\n",
    "def greedy_decode(model, src, max_len, start_symbol, config):\n",
    "\n",
    "    src = src.to(config.device)\n",
    "    memory = model.encoder(src)  # 对输入的Token序列进行解码翻译\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol). \\\n",
    "       type(torch.long).to(config.device)  # 解码的第一个输入，起始符号\n",
    "\n",
    "    for i in range(max_len - 1):\n",
    "        memory = memory.to(config.device)\n",
    "        tgt_mask = (model.my_transformer.generate_square_subsequent_mask(ys.size(0))\n",
    "                   .type(torch.bool)).to(config.device)  # 根据tgt_len产生一个注意力mask矩阵（对称的）\n",
    "        out = model.decoder(ys, memory, tgt_mask)  # [tgt_len,tgt_vocab_size]\n",
    "        out = out.transpose(0, 1)  # [tgt_vocab_size, tgt_len]\n",
    "        prob = model.classification(out[:, -1])  # 只对对预测的下一个词进行分类\n",
    "        _, next_word = torch.max(prob, dim=1)  # 选择概率最大者\n",
    "        next_word = next_word.item()\n",
    "        ys = torch.cat([ys, torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
    "        # 将当前时刻解码的预测输出结果，同之前所有的结果堆叠作为输入再去预测下一个词。\n",
    "        if next_word == config.EOS_IDX:  # 如果当前时刻的预测输出为结束标志，则跳出循环结束预测。\n",
    "            break\n",
    "    return ys\n",
    "\n",
    "def translate_to_right(src, config):\n",
    "    data_loader = VariantWordDataset(\"train\", config.source_dic_path, config.target_dic_path)\n",
    "    translation_model = TranslationModel(src_vocab_size=config.source_vocab_size,\n",
    "                                        tgt_vocab_size=config.target_vocab_size,\n",
    "                                        d_model=config.d_model,\n",
    "                                        nhead=config.num_head,\n",
    "                                         num_encoder_layers=config.num_encoder_layers,\n",
    "                                       num_decoder_layers=config.num_decoder_layers,\n",
    "                                       dim_feedforward=config.dim_feedforward,\n",
    "                                       dropout=config.dropout)\n",
    "    translation_model = translation_model.to(config.device)\n",
    "    torch.load(\"../Weights/model.pkl\", map_location=\"cpu\")\n",
    "    r = translate(translation_model, src, data_loader, config)\n",
    "    return r\n",
    "\n",
    "\n",
    "\n",
    "srcs = [\"9306你好,鉴于你良好的信誉,特聘请你~来我店帮忙工作（350/天）咨询,Q:707941883.\"]\n",
    "tgts = [\"9306你好,鉴于你良好的信誉,特聘请你来我店帮忙工作(350天)咨询,Q:707941883.\"]\n",
    "config = Config()\n",
    "for i, src in enumerate(srcs):\n",
    "    r = translate_to_right(src, config)\n",
    "    print(f\"德语：{src}\")\n",
    "    print(f\"翻译：{r}\")\n",
    "    print(f\"英语：{tgts[i]}\")\n",
    "    # print(len([src]))\n",
    "    # print(len([tgts[i]]))\n",
    "    # print([tgts[i]])\n",
    "    print([[i for i in src]])\n",
    "    print([[[i for i in tgts[i]]]])\n",
    "    print(bleu_score([[i for i in src]], [[[i for i in tgts[i]]]]))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e14cee0ee6a83057731cf0853bdd17c3d89c7b62da788446c49af076e5ce1dd4"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
