{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from Utils import VariantWordDataset, Config\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实例化全局参数 Config 对象\n",
    "config = Config()\n",
    "\n",
    "\n",
    "# 构建数据集\n",
    "train_set = VariantWordDataset(\"train\", config.source_dic_path, config.target_dic_path)\n",
    "valid_set = VariantWordDataset(\"test\", config.source_dic_path, config.target_dic_path)\n",
    "print(f\"Train size: {len(train_set)}\")\n",
    "\n",
    "# 构建data_loader\n",
    "n_cpu = os.cpu_count()\n",
    "train_dataloader = DataLoader(train_set, batch_size=config.batch_size, shuffle=True, collate_fn=train_set.generate_batch, num_workers=n_cpu)\n",
    "valid_dataloader = DataLoader(valid_set, batch_size=config.batch_size, shuffle=False, collate_fn=valid_set.generate_batch, num_workers=n_cpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Model.BaselineModel import BaselineModel\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "# import wandb\n",
    "\n",
    "# 初始化 wandb\n",
    "# wandb.init(project=\"Graduation_project\")\n",
    "\n",
    "# 模型初始化\n",
    "model = BaselineModel(config)\n",
    "\n",
    "# # wandb logger\n",
    "# wandb_logger = WandbLogger(project = \"Graduation_project\",\n",
    "#                            name = 'Transformer-CrossEL-lr-0.02',\n",
    "#                            save_dir = '../Logs',\n",
    "#                            log_model=\"all\")\n",
    "\n",
    "# # 模型参数保存\n",
    "# checkpoint_callback = ModelCheckpoint(\n",
    "#     monitor=\"valid_accuracy\",\n",
    "#     dirpath=\"../Weights\",\n",
    "#     filename=\"Baseline-Transformer-CrossEntropyLoss-{epoch:02d}-{valid_accuracy:.2f}\",\n",
    "#     save_top_k=3,\n",
    "#     mode=\"max\",\n",
    "# )\n",
    "\n",
    "# # 训练 Trainer 定义\n",
    "# trainer = pl.Trainer(\n",
    "#     max_epochs=5, \n",
    "#     gpus=0,\n",
    "#     logger = wandb_logger,\n",
    "#     callbacks=[checkpoint_callback]\n",
    "#     )\n",
    "\n",
    "\n",
    "# # 模型训练\n",
    "# trainer.fit(\n",
    "#     model, \n",
    "#     train_dataloaders=train_dataloader, \n",
    "#     val_dataloaders=valid_dataloader\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "sys.path.append(\"..\")\n",
    "from Model.ConvS2SModel import ConvS2SModel\n",
    "from Utils.Variant_word import VariantWordDataset\n",
    "import torch\n",
    "from Utils.config import Config\n",
    "from torchtext.data.metrics import bleu_score\n",
    "\n",
    "# def translate(model, src, data_loader, config):\n",
    "    \n",
    "#     source_dic = data_loader.source_dic    \n",
    "#     target_dic = data_loader.target_dic\n",
    "\n",
    "#     model.eval()\n",
    "\n",
    "#     tokens = [source_dic.word2idx[i] for i in list(src)] # 构造一个样本\n",
    "#     num_tokens = len(tokens)\n",
    "#     src = (torch.LongTensor(tokens).reshape(num_tokens, 1))  # 将src_len 作为第一个维度\n",
    "#     tgt_tokens = greedy_decode(model, src, max_len=num_tokens + 5,\n",
    "#                                 start_symbol=config.BOS_IDX, config=config).flatten()  # 解码的预测结果\n",
    "    \n",
    "#     return \" \".join([target_dic.idx2word[int(tok)] for tok in tgt_tokens]).replace(\"[BOS]\", \"\").replace(\"[EOS]\", \"\")\n",
    "\n",
    "\n",
    "# def greedy_decode(model, src, max_len, start_symbol, config):\n",
    "\n",
    "#     src = src.to(config.device)\n",
    "#     memory = model.encoder(src)  # 对输入的Token序列进行解码翻译\n",
    "#     ys = torch.ones(1, 1).fill_(start_symbol). \\\n",
    "#        type(torch.long).to(config.device)  # 解码的第一个输入，起始符号\n",
    "\n",
    "#     for i in range(max_len - 1):\n",
    "#         memory = memory.to(config.device)\n",
    "#         tgt_mask = (model.my_transformer.generate_square_subsequent_mask(ys.size(0))\n",
    "#                    .type(torch.bool)).to(config.device)  # 根据tgt_len产生一个注意力mask矩阵（对称的）\n",
    "#         out = model.decoder(ys, memory, tgt_mask)  # [tgt_len,tgt_vocab_size]\n",
    "#         out = out.transpose(0, 1)  # [tgt_vocab_size, tgt_len]\n",
    "#         prob = model.classification(out[:, -1])  # 只对对预测的下一个词进行分类\n",
    "#         _, next_word = torch.max(prob, dim=1)  # 选择概率最大者\n",
    "#         next_word = next_word.item()\n",
    "#         ys = torch.cat([ys, torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
    "#         # 将当前时刻解码的预测输出结果，同之前所有的结果堆叠作为输入再去预测下一个词。\n",
    "#         if next_word == config.EOS_IDX:  # 如果当前时刻的预测输出为结束标志，则跳出循环结束预测。\n",
    "#             break\n",
    "#     return ys\n",
    "\n",
    "# def translate_to_right(src, config):\n",
    "#     data_loader = VariantWordDataset(\"train\", config.source_dic_path, config.target_dic_path)\n",
    "#     translation_model = ConvS2SModel(config)\n",
    "#     translation_model = translation_model.to(config.device)\n",
    "#     torch.load(\"../../Weights_2/ConvS2SModel-CrossEntropyLoss-epoch=11-valid_f1=0.97.ckpt\", map_location=\"cpu\")\n",
    "#     r = translate(translation_model, src, data_loader, config)\n",
    "#     return r\n",
    "\n",
    "\n",
    "config = Config()\n",
    "translation_model = ConvS2SModel(config)\n",
    "translation_model = translation_model.to(config.device)\n",
    "torch.load(\"../../Weights_2/ConvS2SModel-CrossEntropyLoss-epoch=11-valid_f1=0.97.ckpt\", map_location=\"cpu\")\n",
    "\n",
    "\n",
    "\n",
    "srcs = [\"9306你好,鉴于你良好的信誉,特聘请你~来我店帮忙工作（350/天）咨询,Q:707941883.\"]\n",
    "tgts = [\"9306你好,鉴于你良好的信誉,特聘请你来我店帮忙工作(350天)咨询,Q:707941883.\"]\n",
    "for i, src in enumerate(srcs):\n",
    "    r = translate_to_right(src, config)\n",
    "    print(f\"德语：{src}\")\n",
    "    print(f\"翻译：{r}\")\n",
    "    print(f\"英语：{tgts[i]}\")\n",
    "    # print(len([src]))\n",
    "    # print(len([tgts[i]]))\n",
    "    # print([tgts[i]])\n",
    "    print([[i for i in src]])\n",
    "    print([[[i for i in tgts[i]]]])\n",
    "    print(bleu_score([[i for i in src]], [[[i for i in tgts[i]]]]))\n",
    "\n",
    "srcs =  tokens = [source_dic.word2idx[i] for i in list(src)]\n",
    "\n",
    "translation_model(srcs, tgts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "sys.path.append(\"..\")\n",
    "from Model.ConvS2SModel import ConvS2SModel\n",
    "from Utils.Variant_word import VariantWordDataset\n",
    "from Utils.Dictionary import Dictionary\n",
    "import torch\n",
    "from Utils.config import Config\n",
    "from torchtext.data.metrics import bleu_score\n",
    "\n",
    "config = Config()\n",
    "\n",
    "# 字典加载\n",
    "source_dic = Dictionary.load_from_file(\"../Data/source_vocal.pkl\")\n",
    "target_dic = Dictionary.load_from_file(\"../Data/target_vocal.pkl\")\n",
    "\n",
    "\n",
    "\n",
    "# 模型载入\n",
    "# translation_model = ConvS2SModel(config)\n",
    "# translation_model = translation_model.to(\"cpu\")\n",
    "# torch.load(\"../../Weights_2/ConvS2SModel-CrossEntropyLoss-epoch=11-valid_f1=0.97.ckpt\", map_location=\"cpu\")\n",
    "\n",
    "\n",
    "# 测试句子\n",
    "srcs = [\"9306你好,鉴于你良好的信誉,特聘请你~来我店帮忙工作（350/天）咨询,Q:707941883.,特聘请你~来我店帮忙工作（350/天）咨询,Q:707941883.\"]\n",
    "tgts = [\"9306你好,鉴于你良好的信誉,特聘请你来我店帮忙工作(350天)咨询,Q:707941883.9306你好,鉴于你良好的信誉,特聘请你来我店帮忙工作(350天)咨询,Q:707941883.\"]\n",
    "\n",
    "\n",
    "# src = torch.LongTensor([ source_dic.word2idx[i] for i in srcs[0] ]).unsqueeze(0).to(device=\"cpu\")\n",
    "# tgt = torch.LongTensor([ source_dic.word2idx[i] for i in tgts[0] ]).unsqueeze(0).to(device=\"cpu\")\n",
    "\n",
    "# src_length = torch.LongTensor(src.size(0))\n",
    "# type(src_length)\n",
    "\n",
    "\n",
    "\n",
    "for i, src in enumerate(srcs):\n",
    "    print(f\"德语：{srcs}\")\n",
    "    print(f\"英语：{tgts[i]}\")\n",
    "    # print(len([src]))\n",
    "    # print(len([tgts[i]]))\n",
    "    # print([tgts[i]])\n",
    "    print([[i for i in src]])\n",
    "    print([[[i for i in tgts[i]]]])\n",
    "    print(bleu_score([[i for i in src]], [[[i for i in tgts[i]]]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--debug] [--train]\n",
      "                             [--source_dic_path SOURCE_DIC_PATH]\n",
      "                             [--target_dic_path TARGET_DIC_PATH]\n",
      "                             [--src2tgt_path SRC2TGT_PATH]\n",
      "                             [--train_set_path TRAIN_SET_PATH]\n",
      "                             [--train_set_supply_path TRAIN_SET_SUPPLY_PATH]\n",
      "                             [--test_set_path TEST_SET_PATH] [--gpus GPUS]\n",
      "                             [--epochs EPOCHS]\n",
      "                             [--train_val_ratio TRAIN_VAL_RATIO] [--lr LR]\n",
      "                             [--batch_size BATCH_SIZE] [--device DEVICE]\n",
      "                             [--checkpoint_path CHECKPOINT_PATH]\n",
      "                             [--checkpoint_moniter_metirc CHECKPOINT_MONITER_METIRC]\n",
      "                             [--checkpoint_filename CHECKPOINT_FILENAME]\n",
      "                             [--use_logger] [--logs_path LOGS_PATH]\n",
      "                             [--logger_filename LOGGER_FILENAME]\n",
      "                             [--model {RNNSearch,ConvS2S,Transformer}]\n",
      "                             [--enc_emb_dropout ENC_EMB_DROPOUT]\n",
      "                             [--dec_emb_dropout DEC_EMB_DROPOUT]\n",
      "                             [--enc_hid_dropout ENC_HID_DROPOUT]\n",
      "                             [--readout_dropout READOUT_DROPOUT]\n",
      "                             [--enc_ninp ENC_NINP] [--dec_ninp DEC_NINP]\n",
      "                             [--enc_nhid ENC_NHID] [--dec_nhid DEC_NHID]\n",
      "                             [--dec_natt DEC_NATT] [--nreadout NREADOUT]\n",
      "                             [--d_model D_MODEL] [--num_head NUM_HEAD]\n",
      "                             [--num_encoder_layers NUM_ENCODER_LAYERS]\n",
      "                             [--num_decoder_layers NUM_DECODER_LAYERS]\n",
      "                             [--dim_feedforward DIM_FEEDFORWARD]\n",
      "                             [--dropout DROPOUT] [--beta1 BETA1]\n",
      "                             [--beta2 BETA2] [--epsilon EPSILON]\n",
      "                             [--embedding_size EMBEDDING_SIZE]\n",
      "                             [--out_embedding_size OUT_EMBEDDING_SIZE]\n",
      "                             [--max_positions MAX_POSITIONS]\n",
      "                             [--convolutions CONVOLUTIONS]\n",
      "                             [--fconv_dropout FCONV_DROPOUT]\n",
      "                             [--hidden_size HIDDEN_SIZE]\n",
      "                             [--kernel_size KERNEL_SIZE]\n",
      "                             [--enc_layers ENC_LAYERS]\n",
      "                             [--dec_layers DEC_LAYERS]\n",
      "ipykernel_launcher.py: error: argument --fconv_dropout: invalid int value: '/tmp/tmp-15495lyOx28OayzM9.json'\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/argparse.py\", line 2303, in _get_value\n",
      "    result = type_func(arg_string)\n",
      "ValueError: invalid literal for int() with base 10: '/tmp/tmp-15495lyOx28OayzM9.json'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/argparse.py\", line 1775, in parse_known_args\n",
      "    namespace, args = self._parse_known_args(args, namespace)\n",
      "  File \"/usr/lib/python3.6/argparse.py\", line 1981, in _parse_known_args\n",
      "    start_index = consume_optional(start_index)\n",
      "  File \"/usr/lib/python3.6/argparse.py\", line 1921, in consume_optional\n",
      "    take_action(action, args, option_string)\n",
      "  File \"/usr/lib/python3.6/argparse.py\", line 1833, in take_action\n",
      "    argument_values = self._get_values(action, argument_strings)\n",
      "  File \"/usr/lib/python3.6/argparse.py\", line 2274, in _get_values\n",
      "    value = self._get_value(action, arg_string)\n",
      "  File \"/usr/lib/python3.6/argparse.py\", line 2316, in _get_value\n",
      "    raise ArgumentError(action, msg % args)\n",
      "argparse.ArgumentError: argument --fconv_dropout: invalid int value: '/tmp/tmp-15495lyOx28OayzM9.json'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/NING/wnn/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-5-13f03d639202>\", line 6, in <module>\n",
      "    from Model.ConvS2SModel import ConvS2SModel\n",
      "  File \"../Model/__init__.py\", line 2, in <module>\n",
      "    from .RNNSearchModel import RNNSearchModel\n",
      "  File \"../Model/RNNSearchModel.py\", line 6, in <module>\n",
      "    from Networks.RNNSearch import RNNSearch\n",
      "  File \"../Networks/__init__.py\", line 3, in <module>\n",
      "    from .ConvS2S import ConvS2S\n",
      "  File \"../Networks/ConvS2S.py\", line 12, in <module>\n",
      "    config = arg_parse()\n",
      "  File \"../config.py\", line 92, in arg_parse\n",
      "    args = parser.parse_args()\n",
      "  File \"/usr/lib/python3.6/argparse.py\", line 1743, in parse_args\n",
      "    args, argv = self.parse_known_args(args, namespace)\n",
      "  File \"/usr/lib/python3.6/argparse.py\", line 1782, in parse_known_args\n",
      "    self.error(str(err))\n",
      "  File \"/usr/lib/python3.6/argparse.py\", line 2402, in error\n",
      "    self.exit(2, _('%(prog)s: error: %(message)s\\n') % args)\n",
      "  File \"/usr/lib/python3.6/argparse.py\", line 2389, in exit\n",
      "    _sys.exit(status)\n",
      "SystemExit: 2\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/NING/wnn/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/data/NING/wnn/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/data/NING/wnn/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "AttributeError: 'tuple' object has no attribute 'tb_frame'\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/usr/lib/python3.6/argparse.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, action, arg_string)\u001b[0m\n\u001b[1;32m   2302\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2303\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: '/tmp/tmp-15495lyOx28OayzM9.json'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mArgumentError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/usr/lib/python3.6/argparse.py\u001b[0m in \u001b[0;36mparse_known_args\u001b[0;34m(self, args, namespace)\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0mnamespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_known_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnamespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_UNRECOGNIZED_ARGS_ATTR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/argparse.py\u001b[0m in \u001b[0;36m_parse_known_args\u001b[0;34m(self, arg_strings, namespace)\u001b[0m\n\u001b[1;32m   1980\u001b[0m             \u001b[0;31m# consume the next optional and any arguments for it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1981\u001b[0;31m             \u001b[0mstart_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconsume_optional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/argparse.py\u001b[0m in \u001b[0;36mconsume_optional\u001b[0;34m(start_index)\u001b[0m\n\u001b[1;32m   1920\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moption_string\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maction_tuples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1921\u001b[0;31m                 \u001b[0mtake_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moption_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1922\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/argparse.py\u001b[0m in \u001b[0;36mtake_action\u001b[0;34m(action, argument_strings, option_string)\u001b[0m\n\u001b[1;32m   1832\u001b[0m             \u001b[0mseen_actions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1833\u001b[0;31m             \u001b[0margument_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margument_strings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/argparse.py\u001b[0m in \u001b[0;36m_get_values\u001b[0;34m(self, action, arg_strings)\u001b[0m\n\u001b[1;32m   2273\u001b[0m             \u001b[0marg_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg_strings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2274\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2275\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/argparse.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, action, arg_string)\u001b[0m\n\u001b[1;32m   2315\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'invalid %(type)s value: %(value)r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2316\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mArgumentError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mArgumentError\u001b[0m: argument --fconv_dropout: invalid int value: '/tmp/tmp-15495lyOx28OayzM9.json'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-13f03d639202>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConvS2SModel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConvS2SModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTransformerModel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTransformerModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/NING/2022-Graduation-thesis/Model/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mTransformerModel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTransformerModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mRNNSearchModel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRNNSearchModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mConvS2SModel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConvS2SModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/NING/2022-Graduation-thesis/Model/RNNSearchModel.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpytorch_lightning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mNetworks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRNNSearch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRNNSearch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdata_loader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/NING/2022-Graduation-thesis/Networks/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mTranslationModel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTranslationModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mConvS2S\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConvS2S\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mConvS2S_parts\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/NING/2022-Graduation-thesis/Networks/ConvS2S.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg_parse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/NING/2022-Graduation-thesis/config.py\u001b[0m in \u001b[0;36marg_parse\u001b[0;34m()\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/argparse.py\u001b[0m in \u001b[0;36mparse_args\u001b[0;34m(self, args, namespace)\u001b[0m\n\u001b[1;32m   1742\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1743\u001b[0;31m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_known_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1744\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/argparse.py\u001b[0m in \u001b[0;36mparse_known_args\u001b[0;34m(self, args, namespace)\u001b[0m\n\u001b[1;32m   1781\u001b[0m             \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1782\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1783\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/argparse.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, message)\u001b[0m\n\u001b[1;32m   2401\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'prog'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'message'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2402\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%(prog)s: error: %(message)s\\n'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python3.6/argparse.py\u001b[0m in \u001b[0;36mexit\u001b[0;34m(self, status, message)\u001b[0m\n\u001b[1;32m   2388\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_print_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2389\u001b[0;31m         \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSystemExit\u001b[0m: 2",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m/data/NING/wnn/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2036\u001b[0m                            'the full traceback.\\n']\n\u001b[1;32m   2037\u001b[0m                     stb.extend(self.InteractiveTB.get_exception_only(etype,\n\u001b[0;32m-> 2038\u001b[0;31m                                                                      value))\n\u001b[0m\u001b[1;32m   2039\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2040\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/NING/wnn/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mget_exception_only\u001b[0;34m(self, etype, value)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mexception\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m         \"\"\"\n\u001b[0;32m--> 823\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mListTB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstructured_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshow_exception_only\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/NING/wnn/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     chained_exceptions_tb_offset, context)\n\u001b[1;32m    701\u001b[0m                 \u001b[0;34m+\u001b[0m \u001b[0mchained_exception_message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m                 + out_list)\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/NING/wnn/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1436\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/NING/wnn/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1334\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1336\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m             )\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Minimal'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/NING/wnn/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0;32m-> 1193\u001b[0;31m                                                                tb_offset)\n\u001b[0m\u001b[1;32m   1194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m         \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mColors\u001b[0m  \u001b[0;31m# just a shorthand + quicker name lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/NING/wnn/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1150\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/NING/wnn/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "# 翻译测试\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "sys.path.append(\"..\")\n",
    "sys.path.append(\".\")\n",
    "from Model.ConvS2SModel import ConvS2SModel\n",
    "from Model.TransformerModel import TransformerModel\n",
    "from Model.RNNSearchModel import RNNSearchModel\n",
    "import torch\n",
    "from torchtext.data.metrics import bleu_score\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn,Tensor\n",
    "from data_loader import *\n",
    "from Model import *\n",
    "import wandb\n",
    "from config import arg_parse\n",
    "\n",
    "# 模型加载\n",
    "config = arg_parse()\n",
    "config.source_dic_path = \"../Data/source_vocal.pkl\"\n",
    "config.target_dic_path = \"../Data/target_vocal.pkl\"\n",
    "config.src2tgt_path = \"../Data/src_idx2tgt_idx.pkl\"\n",
    "config.train_set_path =  '../Data/Dataset/train_data.csv'\n",
    "config.test_set_path =  '../Data/Dataset/test_data.csv'\n",
    "config.train_set_supply_path =  '../Data/Dataset/train_data_supply_0417.csv'\n",
    "# config.device =  'cpu'\n",
    "config.d_model = 256\n",
    "config.num_head = 8\n",
    "config.num_encoder_layers = 3\n",
    "config.num_decoder_layers = 3\n",
    "config.dim_feedforward = 512\n",
    "\n",
    "\n",
    "# convs2s = ConvS2SModel(config)\n",
    "# convs2s.to(config.device).load_state_dict(torch.load(\"../Weights_ConvS2SModel-CrossEntropyLoss/ConvS2SModel-CrossEntropyLoss-epoch=33-valid_f1=0.98.ckpt\")[\"state_dict\"])\n",
    "# rnnsearch = RNNSearchModel(config)\n",
    "# rnnsearch.to(config.device).load_state_dict(torch.load(\"../Weights_RNNsearchModel-CrossEntropyLoss/RNNsearchModel-CrossEntropyLoss-epoch=34-valid_f1=0.91.ckpt\")[\"state_dict\"])\n",
    "# transformer = TransformerModel(config)\n",
    "# transformer.to(config.device).load_state_dict(torch.load(\"../Weights_TransformerModel-CrossEntropyLoss/TransformerModel-CrossEntropyLoss-epoch=34-valid_f1=0.94.ckpt\")[\"state_dict\"])\n",
    "\n",
    "\n",
    "# 数据集构建\n",
    "train_set = VariantWordDataset(\"train\", config, isAligned=False, supply_ratio=0)\n",
    "valid_set = VariantWordDataset(\"test\", config, isAligned=False)\n",
    "print(f\"Train size: {len(train_set)}\")\n",
    "\n",
    "\n",
    "# dataloader 初始化\n",
    "# 数据传输cpu数目\n",
    "n_cpu = os.cpu_count()\n",
    "train_dataloader = DataLoader(train_set, batch_size=1, shuffle=True, collate_fn=train_set.generate_batch, num_workers=n_cpu)\n",
    "valid_dataloader = DataLoader(valid_set, batch_size=1, shuffle=False, collate_fn=valid_set.generate_batch, num_workers=n_cpu)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def tran_ConvS2S(config, src, tgt, tgt_length, isAligned):\n",
    "\n",
    "    start =time.clock()\n",
    "    src = src.to(config.device).transpose(0,1)  # [ batch_size, src_len ]\n",
    "    tgt = tgt.to(config.device).transpose(0,1)  # [ batch_size, tgt_len ]\n",
    "    src_length = src.size(0)  # [ batch_size ]\n",
    "    tgt_input = tgt[:, 1:-1]  # 解码部分的输入, [ batch_size, tgt_len ]\n",
    "    decoder_out, lprobs  = convs2s(src, src_length, tgt_input)\n",
    "    \n",
    "\n",
    "    tgt_input = tgt_input.reshape(-1)\n",
    "    decoder_out = decoder_out[:,:,:].argmax(axis=2).reshape(-1)\n",
    "    print(decoder_out.device)\n",
    "    decoder_out = np.delete(Tensor.cpu(decoder_out).numpy() , np.where(Tensor.cpu(tgt_input).numpy() <= config.GAP_IDX))\n",
    "    tgt_input = np.delete(Tensor.cpu(tgt_input).numpy() , np.where(Tensor.cpu(tgt_input).numpy() <= config.GAP_IDX))\n",
    "\n",
    "    end = time.clock()\n",
    "\n",
    "    candidate = [str(train_set.target_dic.idx2word[i]) for i in decoder_out.tolist()]\n",
    "    reference = [str(train_set.target_dic.idx2word[i]) for i in tgt_input.tolist()]\n",
    "    print(\"\".join(candidate))\n",
    "    print(\"\".join(reference))\n",
    "    print(bleu_score([candidate], [[reference]]))\n",
    "    print( end )\n",
    "    print( start )\n",
    "    \n",
    "    return bleu_score([candidate], [[reference]]), end - start\n",
    "\n",
    "\n",
    "def create_mask(vector, PAD_IDX):\n",
    "\n",
    "    vector_mask = (vector != PAD_IDX)\n",
    "    return vector_mask\n",
    "\n",
    "def traverse(tensor,  PAD_IDX, tgt_lengths):\n",
    "    # 先去除所有的PAD\n",
    "    new_tensor = []\n",
    "\n",
    "    for i, length in zip(tensor, tgt_lengths.cpu()):\n",
    "        i = i[:length]\n",
    "            # 倒序\n",
    "        new_tensor.append( i.flip(0) )\n",
    "\n",
    "    # PAD\n",
    "    tensor = pad_sequence(new_tensor, padding_value=PAD_IDX, batch_first=True)  # [de_len,batch_size]\n",
    "\n",
    "    return tensor\n",
    "\n",
    "def tran_RNNSearch(config, src, tgt, tgt_length, isAligned):\n",
    "\n",
    "    start =time.clock()\n",
    "\n",
    "    src = src.to(config.device).transpose(0, 1) # [batch_size, src_len]\n",
    "    tgt = tgt.to(config.device).transpose(0, 1)\n",
    "    a = np.delete(Tensor.cpu(tgt).numpy() , np.where(Tensor.cpu(tgt).numpy() <= config.GAP_IDX))\n",
    "    print(a)\n",
    "    reference = [str(train_set.target_dic.idx2word[i]) for i in a.tolist()]\n",
    "    print(\"\".join(reference))\n",
    "    forward_tgt = tgt\n",
    "    backward_tgt = traverse(tgt, config.PAD_IDX, tgt_length)\n",
    "\n",
    "    src_mask = create_mask(src, config.PAD_IDX)\n",
    "    forward_tgt_mask = create_mask(forward_tgt, config.PAD_IDX)\n",
    "    backward_tgt_mask = create_mask(backward_tgt, config.PAD_IDX)\n",
    "\n",
    "        \n",
    "    # logits 输出shape为[tgt_len,batch_size,tgt_vocab_size]\n",
    "    loss, w_loss, output = rnnsearch(\n",
    "        src = src,                   # Encoder的token序列输入，[src_len,batch_size]\n",
    "        src_mask = src_mask, \n",
    "        f_trg = forward_tgt, \n",
    "        f_trg_mask = forward_tgt_mask,\n",
    "        b_trg=backward_tgt, \n",
    "        b_trg_mask=backward_tgt_mask)\n",
    "\n",
    "    output = output[:,1:-1].reshape(-1)\n",
    "    forward_tgt = forward_tgt[:,1:-1].reshape(-1)\n",
    "    print(forward_tgt.shape)\n",
    "    print(output.shape)\n",
    "\n",
    "    output = np.delete(Tensor.cpu(output).numpy() , np.where(Tensor.cpu(forward_tgt).numpy() <= config.GAP_IDX))\n",
    "    forward_tgt = np.delete(Tensor.cpu(forward_tgt).numpy() , np.where(Tensor.cpu(forward_tgt).numpy() <= config.GAP_IDX))\n",
    "\n",
    "    end = time.clock()\n",
    "\n",
    "    candidate = [str(train_set.target_dic.idx2word[i]) for i in output.tolist()]\n",
    "    reference = [str(train_set.target_dic.idx2word[i]) for i in forward_tgt.tolist()]\n",
    "    print(\"\".join(candidate))\n",
    "    print(\"\".join(reference))\n",
    "    # print(bleu_score([candidate], [[reference]]))\n",
    "    return bleu_score([candidate], [[reference]]), end - start\n",
    "\n",
    "def generate_square_subsequent_mask(config, sz):\n",
    "    mask = (torch.triu(torch.ones((sz, sz), device=config.device)) == 1).transpose(0, 1)\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask\n",
    "\n",
    "def create_mask_1(config, src, tgt):\n",
    "    src_seq_len = src.shape[0]\n",
    "    tgt_seq_len = tgt.shape[0]\n",
    "\n",
    "    tgt_mask = generate_square_subsequent_mask(config, tgt_seq_len)\n",
    "    src_mask = torch.zeros((src_seq_len, src_seq_len),device=config.device).type(torch.bool)\n",
    "\n",
    "    src_padding_mask = (src == config.PAD_IDX).transpose(0, 1)\n",
    "    tgt_padding_mask = (tgt == config.PAD_IDX).transpose(0, 1)\n",
    "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask\n",
    "\n",
    "def tran_transformer(config, src, tgt, tgt_length, _):\n",
    "\n",
    "    start =time.clock()\n",
    "    src = src.cuda()\n",
    "    tgt = tgt.cuda()\n",
    "\n",
    "    tgt_input = tgt[:-1, :]  # 解码部分的输入, [tgt_len,batch_size]\n",
    "    src_mask, tgt_mask, src_padding_mask, tgt_padding_mask \\\n",
    "            = create_mask_1(config, src, tgt_input)\n",
    "    \n",
    "    # logits 输出shape为[tgt_len,batch_size,tgt_vocab_size]\n",
    "    logits = transformer(\n",
    "                            src=src,  # Encoder的token序列输入，[src_len,batch_size]\n",
    "                            tgt=tgt_input,  # Decoder的token序列输入,[tgt_len,batch_size]\n",
    "                            src_mask=src_mask,  # Encoder的注意力Mask输入，这部分其实对于Encoder来说是没有用的\n",
    "                            tgt_mask=tgt_mask, # Decoder的注意力Mask输入，用于掩盖当前position之后的position [tgt_len,tgt_len]\n",
    "                            src_key_padding_mask=src_padding_mask,  # 用于mask掉Encoder的Token序列中的padding部分\n",
    "                            tgt_key_padding_mask=tgt_padding_mask,  # 用于mask掉Decoder的Token序列中的padding部分\n",
    "                            memory_key_padding_mask=src_padding_mask)  # 用于mask掉Encoder的Token序列中的padding部分\n",
    "\n",
    "\n",
    "    ### 计算loss\n",
    "    tgt_out = tgt[1:, :]  # 解码部分的真实值  shape: [tgt_len,batch_size]\n",
    "    # loss = self.loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "\n",
    "\n",
    "    decoder_out = np.delete(Tensor.cpu( logits.reshape(-1, logits.shape[-1]).argmax(1)).detach().numpy() , np.where(Tensor.cpu( logits.reshape(-1, logits.shape[-1]).argmax(1)).detach().numpy()  <= config.GAP_IDX))\n",
    "    tgt_out = np.delete(Tensor.cpu(tgt_out).numpy() , np.where(Tensor.cpu(tgt_out).numpy() <= config.GAP_IDX))\n",
    "\n",
    "    end = time.clock()\n",
    "\n",
    "    candidate = [str(train_set.target_dic.idx2word[i]) for i in decoder_out.tolist()]\n",
    "    reference = [str(train_set.target_dic.idx2word[i]) for i in tgt_out.tolist()]\n",
    "    print(\"\".join(candidate))\n",
    "    print(\"\".join(reference))\n",
    "    print(bleu_score([candidate], [[reference]]))\n",
    "    # print(end - start)\n",
    "    return bleu_score([candidate], [[reference]]), end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "赖晚开出(46虎),您中了吗?加微:18683367080我可以告诉你下次的一肖三码,早加就知道\n",
      "昨晚开出(46虎),您中了吗?加微:18683367080我可以告诉你下次的一肖三码,早加就知道\n",
      "0.9784820675849915\n",
      "354.695067\n",
      "354.659237\n",
      "昨晚开出(46虎),您中了?wei:18683367080我可可告诉你下次的一肖三码,早加\n",
      "晚开出(46虎),您中了吗?加微:18683367080我可以告诉你下次的一肖三码,早加就知道\n",
      "0.7600666967065693\n",
      "[3188 3165 1781 2526  262  479  716  109 1086 3283 1881   44 3279 1435\n",
      " 1054 1419  351  453  748 3359  716 3359 2927 2927  716 1587 1480 3359\n",
      " 1480 2440 3081  688 2936  711 2587 1495  317 1711 3185  886 1598 1138\n",
      " 3283  169 1419 1504  318 2824]\n",
      "昨晚开出(46虎),您中了吗?加微:18683367080我可以告诉你下次的一肖三码,早加就知道\n",
      "torch.Size([48])\n",
      "torch.Size([48])\n",
      "昨晚开出(46[GAP]机,您中了解?加wei6833677080[GAP]我可以告你你次次一肖三码,早加就知道\n",
      "昨晚开出(46虎),您中了吗?加微:18683367080我可以告诉你下次的一肖三码,早加就知道\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/NING/wnn/lib/python3.6/site-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "../Model_parts/RNNSearch.py:60: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/cuda/Indexing.cu:963.)\n",
      "  logit.data.masked_fill_(1 - mask, -float('inf'))\n",
      "/data/NING/wnn/lib/python3.6/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0.035829999999975826\n",
      "0.011779999999987467\n",
      "0.08268199999997705\n"
     ]
    }
   ],
   "source": [
    "from torch import nn,Tensor\n",
    "import time\n",
    "time1 =float(0)\n",
    "time2 = float(0)\n",
    "time3 = float(0)\n",
    "times = 0\n",
    "# 计算ConvS2S模型时间\n",
    "for index, (src, tgt, tgt_length, _) in enumerate(valid_dataloader):\n",
    "\n",
    "    if index < 1:\n",
    "        bleu1, timec = tran_ConvS2S(config, src, tgt, tgt_length, _)\n",
    "        bleu1, timet = tran_transformer(config, src, tgt, tgt_length, _)\n",
    "        bleu1, timer = tran_RNNSearch(config, src, tgt, tgt_length, _)\n",
    "\n",
    "        time1+= timec\n",
    "        time2 += timet\n",
    "        time3 += timer\n",
    "        times += 1\n",
    "    else:\n",
    "        break\n",
    "print(times)\n",
    "print(time1/times)\n",
    "print(time2/times)\n",
    "print(time3/times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00023599999997259147"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = \"昨晚开出(46虎),您中了吗?加微:18683367080我可以告诉你下次的一肖三码,早加就知道\"\n",
    "list_1 = list(string)\n",
    "list_2 = []\n",
    "\n",
    "start = time.clock()\n",
    "for i in list_1:\n",
    "    list_2.append(train_set.target_dic.word2idx[i])\n",
    "end = time.clock()\n",
    "end - start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nohup python3 -u train.py --corpus_subpath casieAll --corpus_filename _corpus_nn.pkl --max_epochs 100 --model nnCorefModel --hidden_dim 200 --embeds_dim 400 --distance_dim 20 --use_logger --logger_filename casieAll-nnCoref-6d-MaxSen50-MaxSpan30-K50 --save_checkpoint --checkpoint_name casieAll-nnCoref-6d-MaxSen50-MaxSpan30-K50-{epoch:02d}-{valid_avg_f1:.2f}  >test_run.out 2>&1 &"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e14cee0ee6a83057731cf0853bdd17c3d89c7b62da788446c49af076e5ce1dd4"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
